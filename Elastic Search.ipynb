{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Finder\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\1-aisys.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\10_logiq.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\11_csdiagnostic.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\12_mac2000.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\2_9100cnxt.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\3_mac5500.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\4_seer100.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\5_senopristina.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\6_senobright.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\7_discovery656.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\8_optima220.txt\n",
      "11/27/2020 19:26:34 - INFO - haystack.preprocessor.utils -   Converting data\\9_volusonswift.txt\n",
      "11/27/2020 19:26:35 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.242s]\n"
     ]
    }
   ],
   "source": [
    "# Let's first get some files that we want to use\n",
    "doc_dir = \"data/\"\n",
    "\n",
    "# Convert files to dicts\n",
    "dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
    "\n",
    "# Now, let's write the dicts containing documents to our DB.\n",
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 19:26:51 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "11/27/2020 19:26:56 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "11/27/2020 19:26:57 - INFO - elasticsearch -   POST http://localhost:9200/rethinkl_test1/_search?scroll=5m&size=1000 [status:200 request:0.018s]\n",
      "11/27/2020 19:26:57 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.035s]\n",
      "11/27/2020 19:26:57 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.000s]\n",
      "11/27/2020 19:26:57 - INFO - haystack.document_store.elasticsearch -   Updating embeddings for 12 docs ...\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                  max_seq_len_query=64,\n",
    "                                  max_seq_len_passage=256,\n",
    "                                  batch_size=16,\n",
    "                                  use_gpu=True,\n",
    "                                  embed_title=True,\n",
    "                                  use_fast_tokenizers=True)\n",
    "# Important: \n",
    "# Now that after we have the DPR initialized, we need to call update_embeddings() to iterate over all\n",
    "# previously indexed documents and update their embedding representation. \n",
    "# While this can be a time consuming operation (depending on corpus size), it only needs to be done once. \n",
    "# At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 19:26:27 - INFO - elasticsearch -   PUT http://localhost:9200/rethinkl_test1 [status:200 request:0.250s]\n",
      "11/27/2020 19:26:27 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.016s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"rethinkl_test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c45c4b0eecbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_files_to_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoc_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_wiki_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_paragraphs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_dir' is not defined"
     ]
    }
   ],
   "source": [
    "dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2020 08:22:04 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.350s]\n",
      "11/23/2020 08:22:05 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.114s]\n",
      "11/23/2020 08:22:06 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.092s]\n",
      "11/23/2020 08:22:07 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.059s]\n",
      "11/23/2020 08:22:09 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.061s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2020 11:36:26 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.030s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<haystack.schema.Document at 0x1e72f498488>,\n",
       " <haystack.schema.Document at 0x1e72f68c448>,\n",
       " <haystack.schema.Document at 0x1e72f68c588>,\n",
       " <haystack.schema.Document at 0x1e72f68c4c8>,\n",
       " <haystack.schema.Document at 0x1e72f68c3c8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.query(query=\"Who is Arya Stark?\", filters=None, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.15 Batches/s]\n",
      "11/27/2020 05:58:38 - INFO - elasticsearch -   POST http://localhost:9200/new_docs/_search [status:200 request:0.124s]\n"
     ]
    }
   ],
   "source": [
    "context_list = retriever.retrieve(query=\"Who is Arya Stark?\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fc768de83391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlisted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'listed' is not defined"
     ]
    }
   ],
   "source": [
    "this = listed[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ''\n",
    "for i in range(len(context_list)):\n",
    "    context_list[i] = context_list[i].to_dict()['text'].replace(\"\\n\", \" \")\n",
    "    context += context_list[i] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' === Catelyn Stark === Catelyn Stark is the Lady of Winterfell, wife of Lord Eddard Stark, and mother to his children Robb, Sansa, Arya, Bran, and Rickon. She is the daughter of Lord Hoster Tully of Riverrun; niece to Ser Brynden Tully (also known as the legendary \"Blackfish\") and sister to Lysa Arryn of the Vale and to Edmure Tully. In the HBO television adaptation, she is portrayed by Michelle Fairley.  === Background === Arya is the third child and younger daughter of Eddard and Catelyn Stark and is nine years old at the beginning of the book series.  She has five siblings: an older brother Robb, an older sister Sansa, two younger brothers Bran and Rickon, and an older illegitimate half-brother, Jon Snow. \\'\\'\\'Arya Stark\\'\\'\\' is a fictional character in American author George R. R. Martin\\'s \\'\\'A Song of Ice and Fire\\'\\' epic fantasy novel series.  She is a prominent point of view character in the novels with the third most viewpoint chapters, and is the only viewpoint character to have appeared in every published book of the series. Introduced in 1996\\'s \\'\\'A Game of Thrones\\'\\', Arya is the third child and younger daughter of Lord Eddard Stark and his wife Lady Catelyn Stark.  She is tomboyish, headstrong, feisty, independent, disdains traditional female pursuits, and is often mistaken for a boy.  She wields a smallsword named Needle, a gift from her half-brother, Jon Snow, and is trained in the Braavosi style of sword fighting by Syrio Forel. Arya is portrayed by English actress Maisie Williams in HBO\\'s Emmy-winning television adaptation of the novel series, \\'\\'Game of Thrones\\'\\'.  Her performance has garnered critical acclaim, particularly in the second season for her work opposite veteran actor Charles Dance (Tywin Lannister) when she served as his cupbearer. She is among the most popular characters in either version of the story.  Williams was nominated for a Primetime Emmy Award for Outstanding Supporting Actress in a Drama Series for the role in 2016. She and the rest of the cast were nominated for Screen Actors Guild Awards for Outstanding Performance by an Ensemble in a Drama Series in 2011, 2013, 2014, 2015, 2016 and 2017.  ==Character and appearances== Sansa Stark is the second child and elder daughter of Eddard Stark and Catelyn Stark. She was born and raised in Winterfell, until leaving with her father and sister at the beginning of the series. She was raised with a younger sister Arya Stark, two younger brothers Rickon Stark and Bran Stark, as well as an older brother Robb Stark, and an older illegitimate half-brother, Jon Snow. Raised as a lady, Sansa is traditionally feminine. Sansa\\'s interests are music, poetry, and singing. She strives to become like the heroines of romantic tales by attempting to find a prince, knight, or gentleman to fall in love with. For a companion animal, she owned a direwolf named Lady. However, Lady was killed in place of Arya\\'s direwolf, Nymeria, after Nymeria attacked the Crown Prince, Joffrey Baratheon, and later fled. Sansa has been described as tall, slim, womanly, and beautiful, destined to be a lady or a queen. She has blue eyes and thick auburn hair that she inherits from her mother, who came from House Tully in the Riverlands region prior to her marriage to Eddard Stark. She has her hair dyed dark brown later on while in the Vale, disguised as Alayne Stone, the bastard daughter of Petyr Baelish.  Sansa is 11 years old in \\'\\'A Game of Thrones\\'\\' and nearly 14 in \\'\\'A Feast for Crows\\'\\'. Arguably the most naive of the Stark children at the start of the series, Sansa often finds herself used as a pawn in the machinations of the other characters. However, as the story progresses, she matures and becomes more of a player of the game rather than a pawn for other characters. She is the most beautiful woman in Westeros at the time of the events of \"A Song of Ice and Fire\". \\'\\'\\'Sansa Stark\\'\\'\\' is a fictional character created by American author George R. R. Martin. She is a prominent character in Martin\\'s award-winning \\'\\'A Song of Ice and Fire\\'\\' series. Introduced in \\'\\'A Game of Thrones\\'\\' (1996), Sansa is the elder daughter and second child of Lord Eddard Stark and his wife Lady Catelyn Stark. She subsequently appeared in the following three novels: \\'\\'A Clash of Kings\\'\\' (1998), \\'\\'A Storm of Swords\\'\\' (2000), and \\'\\'A Feast for Crows\\'\\' (2005). While absent from the fifth novel \\'\\'A Dance with Dragons\\'\\', as the books are separated geographically, Sansa is confirmed to return in the forthcoming next book in the series, \\'\\'The Winds of Winter\\'\\'. In HBO\\'s adaptation of the series, \\'\\'Game of Thrones\\'\\', Sansa is portrayed by English actress Sophie Turner. The character has received critical acclaim, including praise as the 4th greatest character in the series by \\'\\'Rolling Stone\\'\\'. She and the rest of the cast were nominated for Screen Actors Guild Awards for Outstanding Performance by an Ensemble in a Drama Series in 2012, 2014, 2015 and 2016. Furthermore, Turner received a nomination for the Primetime Emmy Award for Outstanding Supporting Actress in a Drama Series in 2019. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.retriever.dense import DensePassageRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 14:57:55 - INFO - elasticsearch -   HEAD http://localhost:9200/new_docs [status:200 request:0.017s]\n",
      "11/27/2020 14:57:55 - INFO - elasticsearch -   GET http://localhost:9200/new_docs [status:200 request:0.000s]\n",
      "11/27/2020 14:57:55 - INFO - elasticsearch -   PUT http://localhost:9200/new_docs/_mapping [status:200 request:0.016s]\n",
      "11/27/2020 14:57:55 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.000s]\n",
      "11/27/2020 14:58:02 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "11/27/2020 14:58:09 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"new_docs\")\n",
    "retriever = DensePassageRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.87 Batches/s]\n",
      "11/27/2020 14:58:45 - INFO - elasticsearch -   POST http://localhost:9200/new_docs/_search [status:200 request:0.265s]\n"
     ]
    }
   ],
   "source": [
    "context_list = retriever.retrieve(query=\"Who is Arya Stark?\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.generator.transformers import RAGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 15:00:21 - INFO - filelock -   Lock 2172311605192 acquired on C:\\Users\\gemma/.cache\\torch\\transformers\\6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d487223d242497e859df01238e54b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4602.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2020 15:00:21 - INFO - filelock -   Lock 2172311605192 released on C:\\Users\\gemma/.cache\\torch\\transformers\\6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'facebook/rag-token-nq\\question_encoder_tokenizer'. Make sure that:\n\n- 'facebook/rag-token-nq\\question_encoder_tokenizer' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'facebook/rag-token-nq\\question_encoder_tokenizer' is the correct path to a directory containing relevant tokenizer files\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-df1c3cd09b1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0membed_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\gemma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\haystack\\generator\\transformers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_name_or_path, retriever, generator_type, top_k_answers, max_length, min_length, num_beams, embed_title, prefix, use_gpu)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRAGeneratorType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSEQUENCE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gemma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\tokenization_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mquestion_encoder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question_encoder_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mgenerator_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"generator_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mquestion_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gemma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\users\\gemma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1642\u001b[0m                 \u001b[1;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing relevant tokenizer files\\n\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1643\u001b[0m             )\n\u001b[1;32m-> 1644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/rag-token-nq\\question_encoder_tokenizer'. Make sure that:\n\n- 'facebook/rag-token-nq\\question_encoder_tokenizer' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'facebook/rag-token-nq\\question_encoder_tokenizer' is the correct path to a directory containing relevant tokenizer files\n\n"
     ]
    }
   ],
   "source": [
    "generator = RAGenerator(\n",
    "    model_name_or_path=\"facebook/rag-token-nq\",\n",
    "    use_gpu=False,\n",
    "    top_k_answers=1,\n",
    "    max_length=200,\n",
    "    min_length=2,\n",
    "    embed_title=True,\n",
    "    num_beams=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
